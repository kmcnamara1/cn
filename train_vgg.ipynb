{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "Author: k.mcnamara\n",
    "Date: 12/11/2020\n",
    "\n",
    "This Notebook has cells for training, validating and deploying a model.\n",
    "Calls scripts from model_training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import depdendencies\n",
    "kernel = conda_tensorflow2_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sagemaker\n",
    "import os\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from tensorflow.python.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/model\n"
     ]
    }
   ],
   "source": [
    "os.environ['SM_MODEL_DIR'] = \"/opt/ml/model\"\n",
    "print(os.environ['SM_MODEL_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 bucket URI for training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set S3 address to training data\n",
    "bucket = \"tickercardiology-echocv-sagemaker\"\n",
    "key = \"model-data\"\n",
    "training_data_uri = \"s3://{}/{}/train/\".format(bucket, key)\n",
    "# Set S3 address to validation data\n",
    "validation_data_uri = \"s3://{}/{}/test/\".format(bucket, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize 'keras_model_fn.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow2 estimator \n",
    "\n",
    "Training instance: ml.g4dn.xlarge\n",
    "Base GPU enabled instance for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator2 = TensorFlow(entry_point='keras_model_fn.py',\n",
    "                        role=role,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.g4dn.xlarge', #$0.958\n",
    "                        framework_version='2.1.0',\n",
    "                        py_version='py36',\n",
    "                        hyperparameters={\n",
    "                                        'epochs': 15,\n",
    "                                        'batch_size': 64,\n",
    "                                        'learning_rate': 1e-5},\n",
    "                        script_mode=True,\n",
    "                        model_dir = os.environ['SM_MODEL_DIR'],\n",
    "                        distributions={'parameter_server': {'enabled': True}})\n",
    "\n",
    "bucket = \"sagemaker-ap-southeast-2-611188727347\"\n",
    "key = \"test1\"\n",
    "model_path = \"s3://{}/{}/\".format(bucket, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "### model save path:\n",
    "\n",
    "S3://{sagemaker-ap-southeast-2-611188727347}.{tensorflow-training-year-month-data-hour-minute-second-ms}/output/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator2.fit({'training': training_data_uri, 'validation': validation_data_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy trained model\n",
    "## Load model from S3, if estimator trained in this notebook\n",
    "\n",
    "instance: ml.m5.large\n",
    "\n",
    "Increase instance size if analysing more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor2 = estimator2.deploy(initial_instance_count=1, instance_type='ml.m5.large', endpoint_name='model1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR\n",
    "## Load model from S3, if estimator not trained in this notebook \n",
    "\n",
    "instance: ml.m5.large\n",
    "\n",
    "Increase instance size if analysing more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"sagemaker-ap-southeast-2-611188727347\"\n",
    "key = \"tensorflow-training-2020-11-09-01-37-28-348\"\n",
    "model_path = \"s3://{}/{}/output/model.tar.gz\".format(bucket, key)\n",
    "\n",
    "model = TensorFlowModel(model_data=model_path, \n",
    "                        role=role,\n",
    "                        framework_version='2.1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the endpoints to save resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the .pb and variables from S3\n",
    "# !aws s3 cp s3://sagemaker-ap-southeast-2-611188727347/tensorflow-training-2020-11-06-03-49-07-502/model/1 temp/1 --recursive \n",
    "## Run this in terminal:    tar -C \"$PWD\" -czf model.tar.gz temp/\n",
    "## Copy the tar.gz to the s3://kate//tensorflow-training-date/output/\n",
    "# !aws s3 cp model.tar.gz s3://sagemaker-ap-southeast-2-611188727347/tensorflow-training-2020-11-06-03-49-07-502/output/ "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
